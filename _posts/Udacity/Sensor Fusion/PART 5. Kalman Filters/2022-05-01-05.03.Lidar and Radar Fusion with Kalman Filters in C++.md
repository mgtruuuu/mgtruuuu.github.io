---
title : "05.03 â€” Lidar and Radar Fusion with Kalman Filters in C++"
category :
    - Sensor Fusion
tag : 
    - C++
    - https://www.udacity.com/course/sensor-fusion-engineer-nanodegree--nd313

toc: true  
toc_sticky: true 
use_math : true
---



## 1. Kalman Filters in C++

{% include video id="Hsvzm7zDG_A" provider="youtube" %}





## 2. Intro

{% include video id="G57ZvTBAUL8" provider="youtube" %}

Before proceeding it may be helpful to review some important geometry concepts, which we recently added to the classroom, [here](https://classroom.udacity.com/nanodegrees/nd013/parts/40f38239-66b6-46ec-ae68-03afd8a601c8/modules/87f3782a-0a5b-4568-bcf2-edad2f5fdd76/lessons/60367cb6-526f-4255-a92a-c850038c4675/concepts/5640101a-453e-444a-ab2e-d0554396e36c). Another great resource for geometry and trigonometry can be found [here](http://www.mathwarehouse.com/trigonometry/).





## 3. Lesson Map and Fusion Flow

{% include video id="_u8Vk58VqxY" provider="youtube" %}

### Overview of the Kalman Filter Algorithm Map

![a map of the Kalman Filter algorithm](https://video.udacity-data.com/topher/2017/February/58b4d902_screenshot-from-2017-02-27-19-56-58/screenshot-from-2017-02-27-19-56-58.png "a map of the Kalman Filter algorithm")

Imagine you are in a car equipped with sensors on the outside. The car sensors can detect objects moving around: for example, the sensors might detect a pedestrian, as described in the video, or even a bicycle. For variety, let's step through the Kalman Filter algorithm using the bicycle example.

The Kalman Filter algorithm will go through the following steps:

- **first measurement** - the filter will receive initial measurements of the bicycle's position relative to the car. These measurements will come from a radar or lidar sensor.
- **initialize state and covariance matrices** - the filter will initialize the bicycle's position based on the first measurement.
- then the car will receive another sensor measurement after a time period $\Delta{t}$.
- **predict** - the algorithm will predict where the bicycle will be after time $\Delta{t}$. One basic way to predict the bicycle location after $\Delta{t}$ is to assume the bicycle's velocity is constant; thus the bicycle will have $(\textrm{moved velocity} \cdot \Delta{t})$. In the extended Kalman filter lesson, we will assume the velocity is constant.
- **update** - the filter compares the "predicted" location with what the sensor measurement says. The predicted location and the measured location are combined to give an updated location. The Kalman filter will put more weight on either the predicted location or the measured location depending on the uncertainty of each value.
- then the car will receive another sensor measurement after a time period $\Delta{t}$. The algorithm then does another **predict** and **update** step.





## 4. Lesson Variables and Equations

In order to help you following along with the derivations of the Kalman Filter equations in this lesson, we're providing a handy dandy cheat sheet (actually "sheets", because there are a few pages). I want to call your attention to the resources panel on the left (see the screenshot below) where you can find a PDF copy of this cheat sheet entitled "Sensor Fusion EKF Reference.pdf."

Download it and keep going with the lesson!





## 5. Estimation Problem Refresh

{% include video id="Uwq7_6slV_M" provider="youtube" %}

### Definition of Variables

- $\mathbf{x}$ is the **mean state vector**. For an extended Kalman filter, the mean state vector contains information about the object's position and velocity that you are tracking. It is called the "mean" state vector because position and velocity are represented by a gaussian distribution with mean $\mathbf{x}$.

- $P$ is the **state covariance matrix**, which contains information about the uncertainty of the object's position and velocity. You can think of it as containing standard deviations.

- $k$ represents time steps. So $\mathbf{x_k}$ refers to the object's position and velocity vector at time $k$.

- The notation $(k+1) \vert k$ refers to the prediction step. At time $k+1$, you receive a sensor measurement. Before taking into account the sensor measurement to update your belief about the object's position and velocity, you predict where you think the object will be at time $k+1$. You can predict the position of the object at $k+1$ based on its position and velocity at time $k$. Hence $\mathbf{x_{(k+1) \vert k}}$ means that you have predicted where the object will be at $k+1$ but have not yet taken the sensor measurement into account.

- $\mathbf{x_{k+1}}$ means that you have now predicted where the object will be at time $k+1$ and then used the sensor measurement to update the object's position and velocity.

![](https://video.udacity-data.com/topher/2017/February/58b4bc06_screen-shot-2017-02-27-at-17.52.45/screen-shot-2017-02-27-at-17.52.45.png)





## 6. Kalman Filter Intuition

### Additional Info about the Last Quiz

![](https://video.udacity-data.com/topher/2017/February/58b4bc59_measureupdatequizpost/measureupdatequizpost.png)

Because we have already run a prediction-update iteration with the first sensor at time $k+3$, the output of the second prediction at time $k+3$ will actually be identical to the output from the update step with the first sensor. So, in theory, you could skip the second prediction step and just run a prediction, update, update iteration.

But you'll learn more about that later. First, a bit of math.

{% include video id="ZG8Ya-mCGhI" provider="youtube" %}


### Kalman Filter Intuition

The Kalman equation contains many variables, so here is a high level overview to get some intuition about what the Kalman filter is doing.

- **Prediction**

    Let's say we know an object's current position and velocity , which we keep in the $\mathbf{x}$ variable. Now one second has passed. We can predict where the object will be one second later because we knew the object position and velocity one second ago; we'll just assume the object kept going at the same velocity.

    The $\mathbf{x'} = \mathrm{F}\, \mathbf{x} + \mathbf{\nu}$ equation does these prediction calculations for us.

    But maybe the object didn't maintain the exact same velocity. Maybe the object changed direction, accelerated or decelerated. So when we predict the position one second later, our uncertainty increases. $\mathrm{P'} = \mathrm{F}\, \mathrm{P}\, \mathrm{F^\intercal} + \mathrm{Q}$ represents this increase in uncertainty.

    **Process noise** refers to the uncertainty in the prediction step. We assume the object travels at a constant velocity, but in reality, the object might accelerate or decelerate. The notation $\mathbf{\nu} \sim N(0, \mathrm{Q})$ defines the process noise as a gaussian distribution with mean zero and covariance $\mathrm{Q}$.

- **Update**

    Now we get some sensor information that tells where the object is relative to the car. First we compare where we think we are with what the sensor data tells us $\mathbf{y} = \mathbf{z} - \mathrm{H}\, \mathbf{x'}$.

    The $\mathrm{K}$ matrix, often called the **Kalman filter gain**, combines the uncertainty of where we think we are $\mathrm{P'}$ with the uncertainty of our sensor measurement $\mathrm{R}$. *If our sensor measurements are very uncertain ($\mathrm{R}$ is high relative to $\mathrm{P'}$)*, then the Kalman filter will give more weight to where we think we are: $\mathbf{x'}$. *If where we think we are is uncertain ($\mathrm{P'}$ is high relative to $\mathrm{R}$)*, the Kalman filter will put more weight on the sensor measurement: $\mathbf{z}$.

    **Measurement noise** refers to uncertainty in sensor measurements. The notation $\mathbf{\omega} \sim N(0, \mathrm{R})$ defines the measurement noise as a gaussian distribution with mean zero and covariance $\mathrm{R}$. Measurement noise comes from uncertainty in sensor measurements.


### A Note About the State Transition Function: B u

If you go back to the video, you'll notice that the state transition function was first given as $\mathbf{x'} = \mathrm{F}\, \mathbf{x} + \mathrm{B}\, \mathbf{u} + \mathbf{\nu}$.

But then $\mathrm{B}\, \mathbf{u}$ was crossed out leaving $\mathbf{x'} = \mathrm{F}\, \mathbf{x} + \mathbf{\nu}$.

$\mathrm{B}$ is a matrix called the **control input matrix** and $\mathbf{u}$ is the **control vector**.

As an example, let's say we were tracking a car and we knew for certain how much the car's motor was going to accelerate or decelerate over time; in other words, we had an equation to model the exact amount of acceleration at any given moment. $\mathrm{B}\, \mathbf{u}$ would represent the updated position of the car due to the internal force of the motor. We would use $\mathbf{\nu}$ to represent any random noise that we could not precisely predict like if the car slipped on the road or a strong wind moved the car.

**For the Kalman filter lessons, we will assume that there is no way to measure or know the exact acceleration of a tracked object.** For example, if we were in an autonomous vehicle tracking a bicycle, pedestrian or another car, we would not be able to model the internal forces of the other object; hence, we do not know for certain what the other object's acceleration is. Instead, we will set $\mathrm{B}\, \mathbf{u} = \mathbf{0}$ and represent acceleration as a random noise with mean $\mathbf{\nu}$.





## 7. Kalman Filter Equations in C++ Part 1

### Kalman Filter Equations in C++

Now, let's do a quick refresher of the Kalman Filter for a simple 1D motion case. Let's say that your goal is to track a pedestrian with state xx that is described by a position and velocity.

- **Prediction Step**

    When designing the Kalman filter, we have to define the two linear functions: the state transition function and the measurement function. The state transition function is $\mathbf{x'} = \mathrm{F}\, \mathbf{x} + \textrm{noise}$, where $\mathrm{F} = \begin{pmatrix} 1 & \Delta{t} \\ 0 & 1 \end{pmatrix}$ and 


    









{% include video id="KV4ZdUnOz9I" provider="youtube" %}



## 8. Kalman Filter Equations in C++ Part 2

{% include video id="smRjTGQG2SY" provider="youtube" %}



## 9. State Prediction

{% include video id="_A0NRvmgo3w" provider="youtube" %}



## 10. Process Covariance Matrix

{% include video id="iFcIiqRGaws" provider="youtube" %}



## 11. Laser Measurements Part 1

{% include video id="drbV05qKV8w" provider="youtube" %}



## 12. Laser Measurements Part 2



## 13. Laser Measurements Part 3

{% include video id="gTEQHV_1E2k" provider="youtube" %}



## 14. Laser Measurements Part 4

{% include video id="udsB-13ntY8" provider="youtube" %}



## 15. Radar Measurements

{% include video id="LOz9AaHvB8M" provider="youtube" %}



## 16. Mapping with a Nonlinear Function



## 17. Extended Kalman Filter

{% include video id="nMUd_esBMM8" provider="youtube" %}



## 18. Multivariate Taylor Series Expansion



## 19. Jacobian Matrix Part 1

{% include video id="FeE5cRlMZqU" provider="youtube" %}



## 20. Jacobian Matrix Part 2

{% include video id="pRhuwlMhG3o" provider="youtube" %}



## 21. EKF Algorithm Generalization

{% include video id="co0ZczAuwdM" provider="youtube" %}



## 22. Sensor Fusion General Flow

{% include video id="dcTY4vRg5vo" provider="youtube" %}



## 23. Evaluating KF Performance Part 1

{% include video id="1HieeV8IUv8" provider="youtube" %}



## 24. Evaluating KF Performance 2

{% include video id="1iVBYQ_KWXk" provider="youtube" %}



## 25. Outro

{% include video id="k5VhLE0OoOM" provider="youtube" %}