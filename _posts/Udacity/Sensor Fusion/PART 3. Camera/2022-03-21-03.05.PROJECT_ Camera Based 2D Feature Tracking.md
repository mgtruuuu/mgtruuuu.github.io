---
title : "03.05 â€” PROJECT: Camera Based 2D Feature Tracking"
category :
    - Sensor Fusion
tag : 
    - C++
    - https://www.udacity.com/course/sensor-fusion-engineer-nanodegree--nd313

toc: true  
toc_sticky: true 
use_math : true
---



## 1. Mid-Term Project Introduction

{% include video id="NxhTpozqXIs" provider="youtube" %}


### Objective and Overview


#### Code Walkthrough


### Project Walkthrough: Intro

{% include video id="Fpnova0JrQk" provider="youtube" %}


### Project Walkthrough: Looping Over the Images

{% include video id="X73dYIJ9KeU" provider="youtube" %}


### Project Walkthrough: Extracting Keypoint Descriptors

{% include video id="ZUec2TfcB4s" provider="youtube" %}


### Project Walkthrough: Code Demo

{% include video id="vYMYB8ujoew" provider="youtube" %}



## 2. The Data Buffer

{% include video id="9ndzOpPHxA4" provider="youtube" %}

### Task MP.1

Your first task is to set up the loading procedure for the images, which is currently not optimal. In the student version of the code, we push all images into a vector inside a for-loop and with every new image, the data structure grows. Now imagine you want to process a large image sequence with several thousand images and Lidar point clouds over night - in the current implementation this would push the memory of your computer to its limit and eventually slow down the entire program. So in order to prevent this, we only want to hold a certain number of images in memory so that when a new one arrives, the oldest one is deleted from one end of the vector and the new one is added to the other end. The following figure illustrates the principle.

![](https://video.udacity-data.com/topher/2020/September/5f5f2f98_sf-imageupdates-august2020.002/sf-imageupdates-august2020.002.png)

Please replace the code in section 'TASK MP.1' with an implementation of this principle.



## 3. Keypoint Detection

{% include video id="CVXysH5gHUQ" provider="youtube" %}

### TASK MP.2


### TASK MP.3



## 4. Descriptor Extraction & Matching

{% include video id="w-0hSIMq32o" provider="youtube" %}

### Descriptor Code Walkthrough

{% include video id="Ap6uNX95Ewc" provider="youtube" %}


### TASK MP.4

Your fourth task is to implement a variety of keypoint descriptors to the already implemented BRISK method and make them selectable using the string 'descriptorType'. The methods you must integrate are BRIEF, ORB, FREAK, AKAZE and SIFT. The SURF is not a part of the mid-term project.

- Update: Please note that until recently, SIFT and SURF were heavily patented, and thus could not be freely used in a commercial context. In case you have an older version of the OpenCV installed on your system, you have to `#include <opencv2/xfeatures2d/nonfree.hpp>` in order to use both algorithms. In versions of the OpenCV >= 4.3, SIFT and SURF can be used via `#include <opencv2/xfeatures2d.hpp>`.


### TASK MP.5

Your fifth task will focus on the matching part. The current implementation uses Brute Force matching combined with Nearest-Neighbor selection. You must now add FLANN as an alternative to brute-force as well as the K-Nearest-Neighbor approach.


### TASK MP.6

As your sixth task, you will then implement the descriptor distance ratio test as a filtering method to remove bad keypoint matches.



## 5. Performance Evaluation

{% include video id="OMqg22EGssM" provider="youtube" %}

In this last part of the mid-term project you will document speed and number of matched keypoints for all detector / descriptor combinations with a focus on the preceding vehicle over a sequence of ten images.


### TASK MP.7
Your seventh task is to count the number of keypoints on the preceding vehicle for all 10 images and take note of the distribution of their neighborhood size. Do this for all the detectors you have implemented.


### TASK MP.8

Your eighth task is to count the number of matched keypoints for all 10 images using all possible combinations of detectors and descriptors. In the matching step, use the BF approach with the descriptor distance ratio set to 0.8.


### TASK MP.9

Your ninth task is to log the time it takes for keypoint detection and descriptor extraction. The results must be entered into a spreadsheet and based on this information you will then suggest the TOP3 detector / descriptor combinations as the best choice for our purpose of detecting keypoints on vehicles. Finally, in a short text, please justify your recommendation based on your observations and on the data you collected.



## 6. Mid-Term Project Workspace and Submission

### Build


### Submission




## 7. Camera Based 2D Feature Tracking

{% include video id="gCw2KotW1NQ" provider="youtube" %}




